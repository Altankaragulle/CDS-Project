# Corporate Distress Prediction Using Machine Learning

## ðŸŽ¯ Research Question

Can machine learning models predict corporate financial distress 12 months in advance using CDS spreads, accounting fundamentals, and market data?

**Target Variable**: Binary classification (1 = firm experiences distress in next 12 months, 0 = otherwise)

**Final Performance**: 
- **Recommended Model (Exp 16):** AUC 0.640, Recall 72%, F1 0.420 (Top 10 features)
- **Alternative (Calibrated):** AUC 0.662, Recall 69.1% (29 features, better calibration)
- **Improvement:** 58% better than CDS-only baseline

---

## ðŸš€ Quick Start

### 1. Set Up Environment

**Option A: Using Conda (Recommended for Nuvolos)**
```bash
# Create environment from file
conda env create -f environment.yml

# Activate environment
conda activate cds-distress-prediction
```

**Option B: Using pip (Local development)**
```bash
# Create virtual environment (optional but recommended)
python -m venv .venv
source .venv/bin/activate  # Mac/Linux
# .venv\Scripts\activate   # Windows

# Install dependencies
pip install -r requirements.txt
```

### 2. Run Complete Pipeline

**Default: Pipeline + Experiments (Recommended)**
```bash
python main.py
```
This runs all 15 pipeline steps + 7 optimization experiments.

**Alternative: Experiments only**
```bash
python main.py --experiments-only
```
Skips pipeline steps, runs only experiments (requires existing data).

**What gets executed:**

**Core Pipeline (15 steps):**
- **Data Processing** (Steps 1-4): Inspect, clean, and merge datasets
- **Feature Engineering** (Steps 5-8): Create accounting and market features
- **Target Creation** (Step 9): Define distress events
- **Model Training** (Steps 10-12): Train and optimize models
- **Evaluation** (Steps 13-15): Assess performance and explainability

**Optimization Experiments (7 experiments):**
- **Exp 1:** Reduce overfitting (regularization)
- **Exp 4:** Optimize recall (threshold tuning)
- **Exp 5:** Add temporal features (key contribution)
- **Exp 6:** Combine all optimizations
- **Exp 13:** Calibrate probabilities (deployment-ready)
- **Exp 14:** Cross-validation (stability check)
- **Exp 16:** Feature selection (Top 10 features) â­ **RECOMMENDED MODEL**

### 3. Expected Output

**Core Pipeline:**
- **Trained Models:** `output/models/lightgbm_optimized.pkl`
- **Results:** `output/step13_evaluation_results.csv`
- **Figures:** `report/figures/`

**Default Output (Pipeline + Experiments):**
- **Recommended Model:** `output/experiments/models/exp16_xgboost.pkl` (Top 10 features)
- **Alternative Model:** `output/models/lightgbm_calibrated_isotonic.pkl` (Calibrated)
- **Experiment Results:** `output/experiments/`
- **Experiment Figures:** `report/figures/experiments/`

**Runtime:** 
- Complete run (default): ~30-40 minutes
- Experiments only: ~15-20 minutes

---

## ðŸ“‚ Project Structure

```
CDS Project/
â”œâ”€â”€ main.py                  # â­ Entry point - Run this!
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ FINAL_REPORT.md          # Complete research report
â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚
â”œâ”€â”€ src/                     # Core 15-step pipeline
â”‚   â”œâ”€â”€ step1_data_inspection.py
â”‚   â”œâ”€â”€ step2_data_quality.py
â”‚   â”œâ”€â”€ step3_data_cleaning.py
â”‚   â”œâ”€â”€ step4_data_merging.py
â”‚   â”œâ”€â”€ step5_preprocessing.py
â”‚   â”œâ”€â”€ step6_accounting_features.py
â”‚   â”œâ”€â”€ step7_market_features.py
â”‚   â”œâ”€â”€ step8_feature_validation.py
â”‚   â”œâ”€â”€ step9_target_creation.py
â”‚   â”œâ”€â”€ step10_ml_construction.py
â”‚   â”œâ”€â”€ step11_model_training.py
â”‚   â”œâ”€â”€ step12_model_optimization.py
â”‚   â”œâ”€â”€ step13_model_evaluation.py
â”‚   â”œâ”€â”€ step14_benchmark_comparison.py
â”‚   â””â”€â”€ step15_explainability.py
â”‚
â”œâ”€â”€ experiments/             # Model optimization experiments
â”‚   â”œâ”€â”€ exp1_reduce_overfitting.py
â”‚   â”œâ”€â”€ exp4_optimize_recall.py
â”‚   â”œâ”€â”€ exp5_temporal_features.py      # â­ Key contribution
â”‚   â”œâ”€â”€ exp6_combined_optimization.py
â”‚   â”œâ”€â”€ exp13_model_calibration.py     # ðŸŽ¯ Calibration
â”‚   â”œâ”€â”€ exp14_cross_validation.py      # Stability check
â”‚   â””â”€â”€ exp16_temporal_feature_selection.py  # ðŸ† RECOMMENDED MODEL
â”‚
â”œâ”€â”€ data/                    # Raw data files
â”œâ”€â”€ output/                  # Generated outputs
â”œâ”€â”€ notebooks/               # Jupyter notebooks (optional)
â””â”€â”€ report/                  # Figures and documentation
```

---

## ðŸ“Š Datasets

### 1. Compustat - Quarterly Fundamentals
- **Source**: Compustat North America
- **Frequency**: Quarterly
- **Key Variables**: Assets, liabilities, equity, income, cash, debt, etc.
- **Purpose**: Calculate accounting ratios (leverage, liquidity, profitability)

### 2. CRSP - Security Prices
- **Source**: CRSP Monthly Stock File
- **Frequency**: Monthly
- **Key Variables**: Prices, returns, shares outstanding, market cap
- **Purpose**: Calculate market-based features (volatility, momentum, beta)

### 3. GVKEY-CUSIP Mapping
- **Purpose**: Link Compustat (GVKEY) with CRSP and CDS data (CUSIP)

### 4. CDS Spreads
- **Source**: IHS Markit
- **Frequency**: Quarterly
- **Key Variables**: 5-year senior CDS spreads
- **Purpose**: Create target variable (spread widening)
- **Status**: âœ… Integrated

---

## ðŸ”¬ Advanced: Run Experiments

To reproduce the complete optimization and validation:

```bash
# Core Optimization (5 experiments)
python experiments/exp1_reduce_overfitting.py      # Regularization
python experiments/exp4_optimize_recall.py         # Threshold tuning
python experiments/exp5_temporal_features.py       # Temporal features â­
python experiments/exp6_combined_optimization.py   # Final model ðŸ†
python experiments/exp13_model_calibration.py      # Calibration ðŸŽ¯

# Advanced Validation (2 experiments)
python experiments/exp14_cross_validation.py       # Time-series CV ðŸ“Š
python experiments/exp15_lstm_baseline.py          # Deep learning ðŸ§ 
```

**Or run all experiments:**
```bash
python main.py --with-experiments
```

See `experiments/README.md` for detailed documentation of each experiment.

---

## ðŸ† Key Results

### Recommended Model: XGBoost with Top 10 Features (Exp 16) â­
- **Model:** XGBoost with feature selection (10 features)
- **Test AUC:** 0.640
- **Precision:** 30%, Recall: 72%, F1: 0.420
- **Catches:** 1,054 / 1,463 distressed firms (72%)
- **Improvement:** 58% better than CDS-only baseline
- **Advantages:** Simpler (66% fewer features), faster, more interpretable

### Alternative: Calibrated LightGBM (29 features)
- **Test AUC:** 0.662
- **Recall:** 69.1%, Precision: 32.2%
- **Calibration (ECE):** 0.0140 (excellent)
- **Use when:** Probability estimates are critical

### Top 10 Features (Exp 16):
1. **cds_spread_lag1** - Recent CDS trajectory
2. **altman_z_score** - Financial health
3. **return_1m** - Recent stock performance
4. **volatility_12m** - Market uncertainty
5. **momentum_12m** - Long-term trend
6. **profit_margin** - Profitability
7. **debt_to_assets** - Leverage
8. **cds_spread_lag4** - CDS history
9. **debt_to_equity** - Capital structure
10. **momentum_3m** - Short-term momentum

### Optimization Journey:
- **Baseline:** AUC 0.6481, Recall 46.4%
- **+ Regularization:** Overfitting reduced by 57%
- **+ Threshold tuning:** Recall improved to 72.6%
- **+ Temporal features:** AUC +4.7% (key contribution)
- **+ Calibration:** ECE improved by 93.6%
- **Final:** AUC 0.6622, Recall 69.1% âœ…

---

## ðŸ“ Data Requirements

Place these files in the `data/` folder:
- `CDS firms fundamentals Quarterly.csv` - Compustat quarterly data
- `Security prices.csv` - CRSP market data
- `firm_cusip_mapping_for_cds.csv` - GVKEY-CUSIP mapping
- `GVKEY US Firms csv.csv` - Firm identifiers

**Sample Size:**
- **608 unique firms** (586 train, 538 test)
- **28,247 firm-quarter observations** (21,971 train, 6,276 test)
- **Temporal split:** 2010-2020 (train), 2021-2023 (test)
- **Distress rate:** 19.6% (train), 23.3% (test)

---

## ðŸ§ª Testing & Validation

### Run Unit Tests
Verify data integrity, model correctness, and prevent data leakage:

```bash
# Install testing dependencies
pip install pytest pytest-cov

# Run all tests
pytest tests/ -v

# Run with coverage report
pytest tests/ --cov=src --cov-report=html
open htmlcov/index.html
```

**Test Coverage:**
- âœ… Data leakage prevention (no future information in features)
- âœ… Temporal integrity (strict train/test split)
- âœ… Model predictions validity (probabilities in [0,1])
- âœ… Performance metrics (AUC > 0.5, recall > 0)
- âœ… Reproducibility (consistent results)

### Compute Confidence Intervals
Get statistical confidence intervals for model metrics:

```bash
python src/step13b_confidence_intervals.py
```

This computes 95% confidence intervals via bootstrap (1,000 iterations):
- **AUC:** 0.6677 Â± 0.0187 (95% CI: [0.6248, 0.6996])
- **Recall:** 0.691 Â± 0.023 (95% CI: [0.645, 0.737])
- **Precision:** 0.322 Â± 0.018 (95% CI: [0.286, 0.358])

---

## ðŸ“– Documentation

- **Complete Report:** `FINAL_REPORT.md` - Full methodology and results
- **Experiments:** `experiments/README.md` - Optimization journey details
- **Notebooks:** `notebooks/` - Interactive exploration (optional)
- **Tests:** `tests/` - Unit tests for data integrity and model validation

---

## ðŸ‘¤ Author

Altan Karagulle

---

## ðŸ“… Last Updated

December 1, 2025 - Reorganized for final submission
